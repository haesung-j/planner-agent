import streamlit as st
import pandas as pd
import json
import asyncio
import httpx
import os
import uuid

from client import PlannerAPIClient, ChatMessage

# FastAPI ì„œë²„ URL
API_BASE_URL = os.getenv("BACKEND_API_URL", "http://localhost:8000")
api_client = PlannerAPIClient(base_url=API_BASE_URL)


def display_recommended_places(thread_id):
    """tool_call ê²°ê³¼ë¥¼ streamlitì— í‘œì¶œí•˜ëŠ” í•¨ìˆ˜"""

    # í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    state_data = api_client.get_graph_state(thread_id)

    if not state_data["has_tasks"] or not state_data.get("recommended_places"):
        return None

    recommended_places = state_data["recommended_places"]
    selected_data = None

    if recommended_places:
        st.subheader("ğŸ¢ ì¶”ì²œ ì¥ì†Œ ëª©ë¡")

        df = pd.DataFrame(recommended_places)
        df = df[["name", "reason", "rating", "address", "latitude", "longitude"]]

        # ê³ ìœ í•œ í‚¤ ìƒì„±
        df_key = f"places_{hash(str(recommended_places))}"

        st.write("ğŸ“‹ **ì•„ë˜ í…Œì´ë¸”ì—ì„œ ì›í•˜ëŠ” ì¥ì†Œë¥¼ ì„ íƒí•˜ì„¸ìš”:**")

        # ì„ íƒëœ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì—ì„œ í™•ì¸
        selected_key = f"selected_{df_key}"

        selection_event = st.dataframe(
            df,
            on_select="rerun",
            selection_mode="multi-row",
            key=df_key,
            use_container_width=True,
        )

        # ì„ íƒëœ í–‰ì´ ìˆëŠ”ì§€ í™•ì¸
        if selection_event.selection.rows:
            selected_rows = selection_event.selection.rows
            selected_df = df.iloc[selected_rows]

            # ì„ íƒëœ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state[selected_key] = selected_df

            # ì„ íƒ ì—¬ë¶€ í™•ì¸
            if st.button(
                f"ì„ íƒí•œ {len(selected_rows)}ê°œ ì¥ì†Œë¡œ ê³„ì† ì§„í–‰",
                key=f"continue_{df_key}",
            ):
                selected_data = selected_df.to_dict("records")

                # ì„ íƒ ê²°ê³¼ ì—…ë°ì´íŠ¸
                success = api_client.update_selected_places(thread_id, selected_data)

                if success:
                    return selected_data
                else:
                    return None

    # í•­ìƒ Noneì´ë‚˜ dict listë§Œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    return selected_data


# Streamlit ì•±ì—ì„œ ì‚¬ìš© ì˜ˆì‹œ
def main():
    st.set_page_config(
        page_title="Place Researcher - Human in the Loop", page_icon="ğŸ¤–", layout="wide"
    )

    if not api_client.health_check():
        st.error("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = str(uuid.uuid4())
        print(st.session_state.thread_id)

    # ë©”ì„¸ì§€ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        try:
            chat_messages = api_client.get_chat_history(st.session_state.thread_id)
            st.session_state.messages = [
                {"role": msg.role, "content": msg.content} for msg in chat_messages
            ]
        except Exception as e:
            # ìƒˆë¡œìš´ thread_idì´ê±°ë‚˜ ì„œë²„ì— ê¸°ë¡ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë°°ì—´ë¡œ ì´ˆê¸°í™”
            # print(f"ëŒ€í™” ì´ë ¥ ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.session_state.messages = []

    if "human_in_the_loop" not in st.session_state:
        st.session_state.human_in_the_loop = False

    # ì‚¬ì´ë“œë°”ì— ì„¤ì • ì •ë³´ í‘œì‹œ
    with st.sidebar:
        st.write("**ì„¸ì…˜ ì •ë³´**")
        st.write(f"Thread ID: {st.session_state.thread_id[:8]}...")

        if st.button("ìƒˆ ëŒ€í™” ì‹œì‘"):
            st.session_state.thread_id = str(uuid.uuid4())
            st.session_state.messages = []
            st.rerun()

    # ì´ì „ ë©”ì‹œì§€ë“¤ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if st.session_state.human_in_the_loop:
        state_data = api_client.get_graph_state(st.session_state.thread_id)

        print("^" * 100)
        print(state_data)
        print(st.session_state.thread_id)
        last_message = state_data["tasks"][0]["last_message"]
        if state_data["has_tasks"] and state_data.get("recommended_places"):
            with st.container():
                selected_data = display_recommended_places(st.session_state.thread_id)
                if selected_data:
                    st.success("ì„ íƒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì‘ë‹µì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤...")

                    # ê·¸ë˜í”„ ì¬ê°œ
                    with st.chat_message("assistant"):
                        message_placeholder = st.empty()

                        async def resume_execution():
                            response = ""
                            async for chunk in api_client.resume_graph(
                                st.session_state.thread_id
                            ):
                                response += chunk
                                message_placeholder.markdown(response)

                            # resumeì´ ì™„ë£Œëœ í›„ ë‹¤ì‹œ ìƒíƒœ í™•ì¸
                            state_data = api_client.get_graph_state(
                                st.session_state.thread_id
                            )

                            if state_data["has_tasks"]:
                                # ì—¬ì „íˆ taskê°€ ìˆë‹¤ë©´ ë‹¤ì‹œ human_in_the_loopë¡œ ì„¤ì •
                                st.session_state.human_in_the_loop = True
                                st.rerun()
                            else:
                                # ì •ìƒ ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ë©”ì‹œì§€ ì¶”ê°€
                                st.session_state.messages.append(
                                    {"role": "assistant", "content": response}
                                )
                                st.session_state.human_in_the_loop = False

                        asyncio.run(resume_execution())

        else:
            tool_name = last_message["name"]
            st.info(f"ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            # ë‹¤ë¥¸ toolì˜ ê²½ìš° ê·¸ë˜í”„ ì¬ê°œ
            with st.chat_message("assistant"):
                message_placeholder = st.empty()

                async def resume_execution():
                    response = ""
                    async for chunk in api_client.resume_graph(
                        st.session_state.thread_id
                    ):
                        response += chunk
                        message_placeholder.markdown(response)
                    # resumeì´ ì™„ë£Œëœ í›„ ë‹¤ì‹œ ìƒíƒœ í™•ì¸
                    state_data = api_client.get_graph_state(st.session_state.thread_id)

                    if state_data["has_tasks"]:
                        # ì—¬ì „íˆ taskê°€ ìˆë‹¤ë©´ ë‹¤ì‹œ human_in_the_loopë¡œ ì„¤ì •
                        st.session_state.human_in_the_loop = True
                        st.rerun()  # í˜ì´ì§€ ì¬ì‹¤í–‰ìœ¼ë¡œ ë‹¤ì‹œ ì²˜ë¦¬
                    else:
                        # ì •ìƒ ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ë©”ì‹œì§€ ì¶”ê°€
                        st.session_state.messages.append(
                            {"role": "assistant", "content": response}
                        )
                        st.session_state.human_in_the_loop = False
                    # st.session_state.messages.append(
                    #     {"role": "assistant", "content": response}
                    # )
                    # st.session_state.human_in_the_loop = False
                    # st.rerun()

                asyncio.run(resume_execution())

    # ì‚¬ìš©ì ì…ë ¥
    if query := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("human"):
            st.markdown(query)

        st.session_state.messages.append({"role": "human", "content": query})

        with st.chat_message("assistant"):
            message_placeholder = st.empty()

            async def stream_events():
                full_response = ""
                async for chunk in api_client.chat_stream(
                    query, st.session_state.thread_id
                ):
                    full_response += chunk
                    message_placeholder.markdown(full_response)

                # ì¸í„°ëŸ½íŠ¸ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•˜ê³  tool ê²°ê³¼ í‘œì‹œ
                state_data = api_client.get_graph_state(st.session_state.thread_id)
                print("*" * 100)
                print(state_data)
                if state_data["has_tasks"]:
                    last_message = state_data["tasks"][0]["last_message"]
                    if last_message:
                        print("*" * 100)
                        print("HUMAN IN THE LOOP")
                        st.session_state.human_in_the_loop = True
                    st.rerun()
                else:
                    st.session_state.messages.append(
                        {"role": "assistant", "content": full_response}
                    )
                # if snapshot.tasks:  # interrupt ë°œìƒ ì‹œ
                #     # search_place tool í˜¸ì¶œë¡œ ì¸í•œ interruptì¸ ê²½ìš°,
                #     if (
                #         snapshot.tasks[0].state.values["messages"][-1].name
                #         == "search_place"
                #     ):
                #         st.session_state.human_in_the_loop = True
                #     st.rerun()
                # else:
                #     # ì •ìƒ ì™„ë£Œëœ ê²½ìš° ë©”ì‹œì§€ ì €ì¥
                #     st.session_state.messages.append(
                #         {"role": "assistant", "content": full_response}
                #     )

            asyncio.run(stream_events())


if __name__ == "__main__":
    main()
